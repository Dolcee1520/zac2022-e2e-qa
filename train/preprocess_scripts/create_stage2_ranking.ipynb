{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddde61-f109-455b-b4da-edd7179c8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "import argparse\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import regex as re\n",
    "import json \n",
    "from glob import glob \n",
    "import re \n",
    "from nltk import word_tokenize as lib_tokenizer \n",
    "import string\n",
    "from rank_bm25 import BM25Okapi\n",
    "from pandarallel import pandarallel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, OkapiBM25Model\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "import numpy as np\n",
    "pandarallel.initialize(progress_bar=True, use_memory_fs=False, nb_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345733f-ffba-40fb-a6d7-7aab69d511a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"../za-data/zac2022_train_merged_final.json\"))\n",
    "data = [x for x in data['data'] if x[\"category\"] == \"FULL_ANNOTATION\" and \"wiki/\" in x[\"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bfafe-68c9-4136-9835-f9f74d5a5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_json(path_or_buf = \"../za-data/wikipedia_20220620_cleaned.jsonl\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347df3d9-69cb-459e-84d0-53e0f45c1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk(query, topk = 100):\n",
    "    tokenized_query = query.split()\n",
    "    tfidf_query = tfidf_model[dictionary.doc2bow(tokenized_query)]\n",
    "    scores = bm25_index[tfidf_query]\n",
    "    top_n = np.argsort(scores)[::-1][:topk]\n",
    "    titles = [df_wiki.title.values[i] for i in top_n]\n",
    "    texts = [df_wiki.text.values[i] for i in top_n]\n",
    "    # print(titles)\n",
    "    return titles, texts, scores[top_n]\n",
    "\n",
    "def get_topk_old(query, topk = 100):\n",
    "    tokenized_query = query.split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    top_n = np.argsort(scores)[::-1][:topk]\n",
    "    titles = [df_wiki.title.values[i] for i in top_n]\n",
    "    texts = [df_wiki.text.values[i] for i in top_n]\n",
    "    # print(titles)\n",
    "    return titles, texts\n",
    "\n",
    "\n",
    "dict_map = dict({})  \n",
    "def word_tokenize(text): \n",
    "    global dict_map \n",
    "    words = text.split() \n",
    "    words_norm = [] \n",
    "    for w in words: \n",
    "        if dict_map.get(w, None) is None: \n",
    "            dict_map[w] = ' '.join(lib_tokenizer(w)).replace('``', '\"').replace(\"''\", '\"') \n",
    "        words_norm.append(dict_map[w]) \n",
    "    return words_norm \n",
    " \n",
    "def strip_answer_string(text): \n",
    "    text = text.strip() \n",
    "    while text[-1] in '.,/><;:\\'\"[]{}+=-_)(*&^!~`': \n",
    "        if text[0] != '(' and text[-1] == ')' and '(' in text: \n",
    "            break \n",
    "        if text[-1] == '\"' and text[0] != '\"' and text.count('\"') > 1: \n",
    "            break \n",
    "        text = text[:-1].strip() \n",
    "    while text[0] in '.,/><;:\\'\"[]{}+=-_)(*&^!~`': \n",
    "        if text[0] == '\"' and text[-1] != '\"' and text.count('\"') > 1: \n",
    "            break \n",
    "        text = text[1:].strip() \n",
    "    text = text.strip() \n",
    "    return text \n",
    " \n",
    "def strip_context(text): \n",
    "    text = text.replace('\\n', ' ') \n",
    "    text = re.sub(r'\\s+', ' ', text) \n",
    "    text = text.strip() \n",
    "    return text\n",
    "\n",
    "def post_process(x):\n",
    "    x = \" \".join(word_tokenize(strip_context(x))).strip()\n",
    "    x = x.replace(\"\\n\",\" \")\n",
    "    # x = x.replace(\",\",\"\").replace(\".\",\"\").replace(\"?\",\"\").replace(\"!\",\"\").replace(\")\",\"\").replace(\"(\",\"\")\n",
    "    x = \"\".join([i for i in x if i not in string.punctuation])\n",
    "    x = \" \".join(x.split()[:128])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad1d4a-1438-4f43-80d8-c9e8be07934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(df_wiki.title.progress_apply)\n",
    "df_wiki['title_lower'] = df_wiki['title'].progress_apply(lambda x: x.lower()).parallel_apply(post_process)\n",
    "# df_wiki['context_lower'] = df_wiki['text'].progress_apply(lambda x: x.lower()).parallel_apply(post_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f75a0-0ce8-41f7-b21e-5b584e2653fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "title2idx = dict([(x.strip(),y) for x,y in zip(df_wiki.title, df_wiki.index.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f9a20-7be5-470a-b606-7a98d4b6b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [doc.split() for doc in df_wiki['title_lower']] #simple tokenier\n",
    "bm25_title = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d934d4-1d21-42bd-9954-724ec39f7640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki/Cù_lao_Chàm\n",
      "wiki/Nhà_Hán\n",
      "wiki/Bán_đảo_Ả_Rập\n"
     ]
    }
   ],
   "source": [
    "for x in data:\n",
    "    answer = x['answer'].replace(\"wiki/\",\"\").replace(\"_\",\" \")\n",
    "    if answer not in title2idx:\n",
    "        for title in title2idx.keys():\n",
    "            if answer.lower() == title.lower():\n",
    "                x[\"answer\"] = \"wiki/\"+title.replace(\" \",\"_\")\n",
    "                print(x[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976486a-ad31-4c70-a385-96067d66a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"query\"] = [post_process(x[\"short_candidate\"]).lower().split() for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d7830-83e1-4224-88b4-4b17678140d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk(query, topk=10):\n",
    "    scores = bm25_title.get_scores(query)\n",
    "    top_titles = np.argsort(scores)[::-1][:topk]\n",
    "    return top_titles, scores[top_titles]\n",
    "df[\"top_n\"] = df[\"query\"].parallel_apply(lambda x: get_topk(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a83835-9e30-46d4-8a99-c89d6fbb00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 10\n",
    "total = 0\n",
    "candidate_ids = []\n",
    "true_ids = []\n",
    "for i, x in tqdm(enumerate(data)):\n",
    "    true_title = x[\"answer\"].replace(\"_\",\" \").replace(\"wiki/\",\"\").strip()\n",
    "    top_n = df.iloc[i].top_n \n",
    "    true_idx = title2idx[true_title]\n",
    "    true_ids.append(true_idx)\n",
    "    candidate_ids.append(list(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ed7ac-27d3-4917-9d05-bf14d2bb9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(candidate_ids, true_ids):\n",
    "    if y not in x:\n",
    "        x[-1] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d625b-b58a-4c0e-a336-ea91ec5b6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "questions = []\n",
    "answers = []\n",
    "titles = []\n",
    "candidates = []\n",
    "labels = []\n",
    "groups = []\n",
    "for idx, (sample, true_idx, candidate_idxs) in tqdm(enumerate(zip(data, true_ids, candidate_ids))):\n",
    "    assert true_idx in candidate_idxs\n",
    "    question = sample['question']\n",
    "    answer = sample['short_candidate']\n",
    "    title = [df_wiki.title.values[i] for i in candidate_idxs]\n",
    "    candidate = [df_wiki.text.values[i] for i in candidate_idxs]\n",
    "    label = [1 if x == true_idx else 0 for x in candidate_idxs]\n",
    "    \n",
    "    questions.extend([question,]*len(candidate_idxs))\n",
    "    answers.extend([answer,]*len(candidate_idxs))\n",
    "    groups.extend([idx,]*len(candidate_idxs))\n",
    "    titles.extend(title)\n",
    "    candidates.extend(candidate)\n",
    "    labels.extend(label)\n",
    "    \n",
    "df[\"question\"] = questions \n",
    "df[\"answer\"] = answers \n",
    "df[\"title\"] = titles \n",
    "df[\"candidate\"] = candidates \n",
    "df[\"label\"] = labels \n",
    "df[\"group\"] = groups \n",
    "df.candidate = df.candidate.apply(lambda x: \" \".join(x.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879eb2b-795c-48ff-9768-d127ee84bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/train_stage2_ranking.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2181b-5479-4cef-a017-13781db87c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -halt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad06dfc-ca65-482e-8e4b-95c8ecf2dbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
